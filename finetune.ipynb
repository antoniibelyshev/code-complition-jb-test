{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/.local/lib/rolos-ml-p39/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PhiForCausalLM, AutoTokenizer\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/phi-1_5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = PhiForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for kotlin files...\n",
      "Parsing functions in kotlin files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54432/54432 [11:41<00:00, 77.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse errors count: 18912, declaration errors count: 0\n",
      "total number of samples: 60051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kotlin_code = utils.extract_kotlin_code()\n",
    "train_kotlin_prompts, test_kotlin_prompts, train_kotlin_answers, test_kotlin_answers = train_test_split(*kotlin_code, test_size=1000, random_state=42)\n",
    "\n",
    "train_dataset = utils.CodeCompletionDataset(train_kotlin_prompts, train_kotlin_answers, train=True)\n",
    "\n",
    "test_kotlin_dataset = utils.CodeCompletionDataset(test_kotlin_prompts, test_kotlin_answers, train=False)\n",
    "\n",
    "test_codexglue_dataset = utils.CodeCompletionDataset(*utils.read_codexglue_test_data(n=1000), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:11<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.0\n",
      "bleu score: 0.0056283212581165545\n",
      "rouge: 0.2210622061584594\n",
      "\n",
      "example prompt:\n",
      "def debug(user, message):\n",
      "    \"\"\"\n",
      "    Adds a message with the ``DEBUG`` level.\n",
      "    \n",
      "    :param user: User instance\n",
      "    :param message: Message to show\n",
      "    \"\"\"\n",
      "    \n",
      "\n",
      "example completion:\n",
      "if user.level == 'DEBUG':\n",
      "        user.log.debug(message)\n",
      "    \n",
      "\n",
      "example true answer:\n",
      "message_user(user, message, constants.DEBUG)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in utils.evaluate(model, tokenizer, test_codexglue_dataset, max_new_tokens=20).items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "prompt, answer = test_codexglue_dataset[0]\n",
    "print(f\"\\nexample prompt:\\n{prompt}\\n\")\n",
    "print(f\"example completion:\\n{utils.sample(model, tokenizer, prompt, min_new_tokens=2, max_new_tokens=20)}\\n\")\n",
    "print(f\"example true answer:\\n{answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:03<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.0\n",
      "bleu score: 0.001848171824365358\n",
      "rouge: 0.07783621991431407\n",
      "\n",
      "example prompt: fun createMutableListFrom(array: dynamic): MutableList<E> \n",
      "\n",
      "example completion: \n",
      "    {\n",
      "        var list = new MutableList<E>();\n",
      "        for (\n",
      "\n",
      "example true answer: TODO(\"Use WITH_STDLIB pragma to use this function\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in utils.evaluate(model, tokenizer, test_kotlin_dataset, max_new_tokens=20).items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "prompt, answer = test_kotlin_dataset[0]\n",
    "print(f\"\\nexample prompt: {prompt}\\n\")\n",
    "print(f\"example completion: {utils.sample(model, tokenizer, prompt, min_new_tokens=2, max_new_tokens=20)}\\n\")\n",
    "print(f\"example true answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1w4ee1vr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: run finetune/1w4ee1vr not found during createRunFiles (<Response [404]>)\n",
      "wandb: ERROR Error while calling W&B API: run finetune/1w4ee1vr not found during createRunFiles (<Response [404]>)\n",
      "wandb: ERROR Error while calling W&B API: run finetune/1w4ee1vr not found during createRunFiles (<Response [404]>)\n",
      "wandb: ERROR Error while calling W&B API: run finetune/1w4ee1vr not found during createRunFiles (<Response [404]>)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅▃▁▁▂▃▂▂▃▃▂▂▃▂▄▁▆▄▂▄▂▅▆▂▂█▇▃▄▃▅▃▄▃▄▄▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.82764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hokey-womprat-25</strong> at: <a href='https://wandb.ai/antonii-belyshev/finetune/runs/1w4ee1vr' target=\"_blank\">https://wandb.ai/antonii-belyshev/finetune/runs/1w4ee1vr</a><br/> View project at: <a href='https://wandb.ai/antonii-belyshev/finetune' target=\"_blank\">https://wandb.ai/antonii-belyshev/finetune</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240505_105217-1w4ee1vr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1w4ee1vr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/coder/project/wandb/run-20240505_105336-4m0evspf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antonii-belyshev/finetune/runs/4m0evspf' target=\"_blank\">hokey-force-26</a></strong> to <a href='https://wandb.ai/antonii-belyshev/finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antonii-belyshev/finetune' target=\"_blank\">https://wandb.ai/antonii-belyshev/finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antonii-belyshev/finetune/runs/4m0evspf' target=\"_blank\">https://wandb.ai/antonii-belyshev/finetune/runs/4m0evspf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.6558: 100%|██████████| 29526/29526 [1:25:11<00:00,  5.78it/s]  \n",
      "Epoch [2/2], Loss: 0.3602: 100%|██████████| 29526/29526 [1:25:01<00:00,  5.79it/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▂▂▂▄▅▂▄▂▂▃▃▁▂▂▂▃▂▂▄▂▄▂█▂▂▃▂▂▂▂▂▂▁▂▂▂▁▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.36022</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hokey-force-26</strong> at: <a href='https://wandb.ai/antonii-belyshev/finetune/runs/4m0evspf' target=\"_blank\">https://wandb.ai/antonii-belyshev/finetune/runs/4m0evspf</a><br/> View project at: <a href='https://wandb.ai/antonii-belyshev/finetune' target=\"_blank\">https://wandb.ai/antonii-belyshev/finetune</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240505_105336-4m0evspf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "finished_epochs = 0\n",
    "for i in range(6, -1, -1):\n",
    "    if os.path.isdir(f\"./checkpoint_after_epoch_{i}\"):\n",
    "        model = PhiForCausalLM.from_pretrained(f\"./checkpoint_after_epoch_{i}\").to(device)\n",
    "        finished_epochs = i + 1\n",
    "        break\n",
    "\n",
    "model = utils.train_model(model, tokenizer, train_dataset, learning_rate=1e-4 * 0.5 ** finished_epochs, start_epoch=finished_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:33<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.0\n",
      "bleu score: 0.0020034207402879678\n",
      "rouge: 0.19129313454196817\n",
      "\n",
      "example prompt: def debug(user, message):\n",
      "    \"\"\"\n",
      "    Adds a message with the ``DEBUG`` level.\n",
      "    \n",
      "    :param user: User instance\n",
      "    :param message: Message to show\n",
      "    \"\"\"\n",
      "    \n",
      "\n",
      "example completion: if (user.isVerbose):\n",
      "        user.log.debug(message)\n",
      "\n",
      "\n",
      "example true answer: message_user(user, message, constants.DEBUG)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in utils.evaluate(model, tokenizer, test_codexglue_dataset, max_new_tokens=20).items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "prompt, answer = test_codexglue_dataset[0]\n",
    "print(f\"\\nexample prompt: {prompt}\\n\")\n",
    "print(f\"example completion: {utils.sample(model, tokenizer, prompt, min_new_tokens=2, max_new_tokens=20)}\\n\")\n",
    "print(f\"example true answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:28<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.014\n",
      "bleu score: 0.00045317261070564204\n",
      "rouge: 0.11821222754168945\n",
      "\n",
      "example prompt: fun createMutableListFrom(array: dynamic): MutableList<E> \n",
      "\n",
      "example completion: ile(array)\n",
      "\n",
      "example true answer: TODO(\"Use WITH_STDLIB pragma to use this function\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in utils.evaluate(model, tokenizer, test_kotlin_dataset, max_new_tokens=20).items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "prompt, answer = test_kotlin_dataset[0]\n",
    "print(f\"\\nexample prompt: {prompt}\\n\")\n",
    "print(f\"example completion: {utils.sample(model, tokenizer, prompt, min_new_tokens=2, max_new_tokens=20)}\\n\")\n",
    "print(f\"example true answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
